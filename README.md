Microexpresiones

Este repositorio contiene un proyecto de detecciÃ³n y anÃ¡lisis de
microexpresiones faciales.
Incluye scripts para preprocesamiento de videos, anotaciones, extracciÃ³n
de caracterÃ­sticas, entrenamiento de un modelo SVM y pruebas de
inferencia en cÃ¡mara.

------------------------------------------------------------------------

ğŸ“‚ Estructura del proyecto

    â”œâ”€â”€ .venv/                   # Entorno virtual (ignorado en git)
    â”œâ”€â”€ annotations/             # Archivos de anotaciones (labels)
    â”œâ”€â”€ data_raw/                # Dataset original (videos/imÃ¡genes sin procesar)
    â”œâ”€â”€ features/                # CaracterÃ­sticas extraÃ­das (features)
    â”œâ”€â”€ models/                  # Modelos entrenados (ej: svm_model.joblib)
    â”œâ”€â”€ rois/                    # Regiones de interÃ©s (imagenes recortadas)
    â”œâ”€â”€ src/                     # CÃ³digo fuente
    â”‚   â”œâ”€â”€ check_env.py
    â”‚   â”œâ”€â”€ compute_features.py
    â”‚   â”œâ”€â”€ infer_camera.py
    â”‚   â”œâ”€â”€ inspect_casme2.py
    â”‚   â”œâ”€â”€ inspect_samm.py
    â”‚   â”œâ”€â”€ make_casme_annotations.py
    â”‚   â”œâ”€â”€ make_samm_annotations.py
    â”‚   â”œâ”€â”€ preprocess_videos.py
    â”‚   â”œâ”€â”€ train_svm.py
    â”‚   â””â”€â”€ utils.py
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ config.yaml              # ConfiguraciÃ³n general
    â”œâ”€â”€ requirements.txt         # Dependencias necesarias

------------------------------------------------------------------------

âš™ï¸ InstalaciÃ³n

1.  Clonar el repositorio:

        git clone https://github.com/SofiaAlvarezS/Microexpresiones.git
        cd Microexpresiones

2.  Crear entorno virtual (recomendado):

        python -m venv .venv

3.  Activar el entorno virtual:

    -   En Windows (PowerShell):

            .venv\Scripts\activate

    -   En Linux/Mac:

            source .venv/bin/activate

4.  Instalar dependencias:

        pip install -r requirements.txt

5.  Verificar instalaciÃ³n:

        python src/check_env.py

------------------------------------------------------------------------

ğŸ“Š Uso de datasets

-   Coloca tus videos o imÃ¡genes originales en data_raw/.
-   El preprocesamiento extraerÃ¡ ROIs en la carpeta rois/.
    -   Si no existe, crÃ©ala:

            mkdir rois
-   Las features procesadas se guardarÃ¡n en features/.
-   Los modelos entrenados se guardan en models/.

âš ï¸ Nota: Ya hay un modelo entrenado (svm_model.joblib). Puedes usarlo
directamente o reentrenar con nuevos datos.

------------------------------------------------------------------------

ğŸš€ CÃ³mo usar los scripts

1.  Preprocesar videos:

        python src/preprocess_videos.py

2.  Generar anotaciones (ejemplos con datasets especÃ­ficos):

        python src/make_casme_annotations.py
        python src/make_samm_annotations.py

3.  Extraer caracterÃ­sticas:

        python src/compute_features.py

4.  Entrenar modelo SVM:

        python src/train_svm.py

5.  Inferencia con cÃ¡mara en vivo:

        python src/infer_camera.py

------------------------------------------------------------------------

ğŸ“Œ Notas

-   No subas datasets completos al repo.
    Se recomienda mantenerlos locales o usar Git LFS para archivos
    pesados.

-   Ajusta rutas y parÃ¡metros en config.yaml.

------------------------------------------------------------------------
