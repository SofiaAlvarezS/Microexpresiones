# Proyecto de Microexpresiones

Este proyecto permite el preprocesamiento, anotaciÃ³n, extracciÃ³n de caracterÃ­sticas y entrenamiento de un modelo SVM para la detecciÃ³n de microexpresiones faciales, utilizando datasets como **CASME2** y **SAMM_v1**.

---

## ğŸ“‚ Estructura del Proyecto

```
Microexpresiones/
â”‚
â”œâ”€â”€ annotations/          # Archivos de anotaciones procesadas
â”œâ”€â”€ data_raw/             # Datasets originales (NO se suben a GitHub)
â”‚   â”œâ”€â”€ CASME2/
â”‚   â””â”€â”€ SAMM_v1/
â”œâ”€â”€ features/             # Features generados a partir de los videos
â”œâ”€â”€ models/               # Modelos entrenados (ej. SVM)
â”‚   â””â”€â”€ svm_model.joblib
â”œâ”€â”€ rois/                 # Regiones de interÃ©s (ROIs) procesadas
â”œâ”€â”€ src/                  # Scripts principales
â”‚   â”œâ”€â”€ check_env.py
â”‚   â”œâ”€â”€ compute_features.py
â”‚   â”œâ”€â”€ infer_camera.py
â”‚   â”œâ”€â”€ inspect_casme2.py
â”‚   â”œâ”€â”€ inspect_samm.py
â”‚   â”œâ”€â”€ make_casme_annotations.py
â”‚   â”œâ”€â”€ make_samm_annotations.py
â”‚   â”œâ”€â”€ preprocess_videos.py
â”‚   â”œâ”€â”€ train_svm.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ config.yaml           # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ requirements.txt      # Dependencias del entorno
â””â”€â”€ .gitignore            # Archivos y carpetas ignoradas por Git
```

---

## âš™ï¸ InstalaciÃ³n

1. Clona el repositorio:

```bash
git clone https://github.com/SofiaAlvarezS/Microexpresiones.git
cd Microexpresiones
```

2. Crea y activa un entorno virtual:

```bash
python -m venv .venv
# En Windows (PowerShell)
.venv\Scripts\activate
# En Linux/Mac
source .venv/bin/activate
```

3. Instala las dependencias:

```bash
pip install -r requirements.txt
```

4. (Opcional) Verifica el entorno:

```bash
python src/check_env.py
```

---

## ğŸ“‚ Datasets

Este proyecto trabaja con datasets de microexpresiones como **CASME2** y **SAMM_v1**.  
Debes organizarlos en la carpeta `data_raw/` de la siguiente manera:

```
data_raw/
â”‚
â”œâ”€â”€ CASME2/
â”‚   â”œâ”€â”€ ... videos e imÃ¡genes originales ...
â”‚
â””â”€â”€ SAMM_v1/
    â”œâ”€â”€ ... videos e imÃ¡genes originales ...
```

### âš ï¸ Importante
- Los datasets **NO estÃ¡n incluidos en este repositorio** por su tamaÃ±o y restricciones de licencia.  
- **No subas los datasets a GitHub**. La carpeta `data_raw/` estÃ¡ listada en `.gitignore`, asÃ­ que Git no los rastrea.  
- Cada miembro del grupo debe descargar los datasets manualmente desde las fuentes oficiales o desde un link compartido (Google Drive, OneDrive, Mega, etc.) y colocarlos dentro de `data_raw/`.

### ğŸ“ Fuentes oficiales
- **CASME2**: [http://casme2.com](http://casme2.com)  
- **SAMM**: [https://sammlab.com](https://sammlab.com)  

---

## â–¶ï¸ Uso

### 1. Preprocesar videos
```bash
python src/preprocess_videos.py
```

### 2. Generar anotaciones
```bash
python src/make_casme_annotations.py
python src/make_samm_annotations.py
```

### 3. Extraer caracterÃ­sticas
```bash
python src/compute_features.py
```

### 4. Entrenar el modelo
```bash
python src/train_svm.py
```

### 5. Inferencia en cÃ¡mara en vivo
```bash
python src/infer_camera.py
```

---

## ğŸ“Œ Notas adicionales

- La carpeta `rois/` se genera automÃ¡ticamente con las regiones de interÃ©s extraÃ­das de los videos.  
- Si ya tienes el modelo `svm_model.joblib` entrenado en `models/`, no necesitas volver a entrenar a menos que quieras actualizarlo con nuevos datos.  
- AsegÃºrate de que tu entorno estÃ© activado cada vez que ejecutes un script (`.venv`).
-   No subas datasets completos al repo.
    Se recomienda mantenerlos locales o usar Git LFS para archivos
    pesados.
-   Ajusta rutas y parÃ¡metros en config.yaml.

------------------------------------------------------------------------
